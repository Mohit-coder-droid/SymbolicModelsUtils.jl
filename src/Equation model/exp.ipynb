{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf4b74c",
   "metadata": {},
   "source": [
    "### Starting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed19076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7152a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_list = [\"sin\", \"cos\", \"sec\", \"csc\", \"tan\", \"cot\", \"log\", \"exp\", \"sqrt\", \"sinh\", \"cosh\", \"sech\", \"csch\", \"tanh\", \"coth\", \"atan\", \"asin\", \"acos\", \"asinh\", \"acosh\", \"atanh\", \"acoth\", \"asech\", \"acsch\"]\n",
    "basic_diadic = [\"+\", \"-\", \"/\", \"*\", \"^\",\"~\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c42495",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "token_dict['[NUM]'] = 1\n",
    "token_dict.update({chr(i + 96): i+1 for i in range(1, 27)})\n",
    "token_dict.update({chr(i + 64): i+len(token_dict)+1 for i in range(1, 27)})\n",
    "token_dict.update({op:i+len(token_dict)+2 for i,op in enumerate(func_list + basic_diadic)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3861055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expression: (cot(x) - tan(x)) / (1 + cos(4x))\n",
    "input_tree = ['/', '+', 'cot', 'x', '*', '-1', 'tan', 'x', '+', '1', 'cos', '*', '4', 'x']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b3a2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_float(s, return_num=False):\n",
    "    try:\n",
    "        s = float(s)\n",
    "        if return_num:\n",
    "            return s\n",
    "        else:\n",
    "            return 1\n",
    "    except:\n",
    "        if return_num:\n",
    "            return s\n",
    "        else:\n",
    "            return token_dict[s]\n",
    "        \n",
    "def classify_operation(token):\n",
    "    if token==1:\n",
    "        return 1  # it's a number\n",
    "    elif 1<token<55:\n",
    "        return 2  # it's a symbolic variable\n",
    "    elif 55<=token<61:\n",
    "        return 3  # it's a trignometric operator\n",
    "    elif 61<=token<64:\n",
    "        return 4  # it's a log, exp, sqrt\n",
    "    elif 64<=token<70:\n",
    "        return 5  # it's a hyperbolic operator\n",
    "    elif 70<=token<79:\n",
    "        return 6  # it's a inverse operator\n",
    "    elif 79<=token<85:\n",
    "        return 7  # it's binary operator\n",
    "    \n",
    "def isoperator(token):\n",
    "    if token<55:\n",
    "        return 0 # not an operator\n",
    "    else:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e8a5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_feature(node, return_num=False):\n",
    "\n",
    "    token = make_float(node, return_num)\n",
    "\n",
    "    return [token, isoperator(token), classify_operation(token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c585c022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[84, 1, 7]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_feature(\"~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43d4e2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[NUM]': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27,\n",
       " 'A': 29,\n",
       " 'B': 30,\n",
       " 'C': 31,\n",
       " 'D': 32,\n",
       " 'E': 33,\n",
       " 'F': 34,\n",
       " 'G': 35,\n",
       " 'H': 36,\n",
       " 'I': 37,\n",
       " 'J': 38,\n",
       " 'K': 39,\n",
       " 'L': 40,\n",
       " 'M': 41,\n",
       " 'N': 42,\n",
       " 'O': 43,\n",
       " 'P': 44,\n",
       " 'Q': 45,\n",
       " 'R': 46,\n",
       " 'S': 47,\n",
       " 'T': 48,\n",
       " 'U': 49,\n",
       " 'V': 50,\n",
       " 'W': 51,\n",
       " 'X': 52,\n",
       " 'Y': 53,\n",
       " 'Z': 54,\n",
       " 'sin': 55,\n",
       " 'cos': 56,\n",
       " 'sec': 57,\n",
       " 'csc': 58,\n",
       " 'tan': 59,\n",
       " 'cot': 60,\n",
       " 'log': 61,\n",
       " 'exp': 62,\n",
       " 'sqrt': 63,\n",
       " 'sinh': 64,\n",
       " 'cosh': 65,\n",
       " 'sech': 66,\n",
       " 'csch': 67,\n",
       " 'tanh': 68,\n",
       " 'coth': 69,\n",
       " 'atan': 70,\n",
       " 'asin': 71,\n",
       " 'acos': 72,\n",
       " 'asinh': 73,\n",
       " 'acosh': 74,\n",
       " 'atanh': 75,\n",
       " 'acoth': 76,\n",
       " 'asech': 77,\n",
       " 'acsch': 78,\n",
       " '+': 79,\n",
       " '-': 80,\n",
       " '/': 81,\n",
       " '*': 82,\n",
       " '^': 83,\n",
       " '~': 84}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59a64781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/', '+', 'cot', 'x', '*', '-1', 'tan', 'x', '+', '1', 'cos', '*', '4', 'x']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2233e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[81, 1, 7],\n",
       " [79, 1, 7],\n",
       " [60, 1, 3],\n",
       " [25, 0, 2],\n",
       " [82, 1, 7],\n",
       " [1, 0, 1],\n",
       " [59, 1, 3],\n",
       " [25, 0, 2],\n",
       " [79, 1, 7],\n",
       " [1, 0, 1],\n",
       " [56, 1, 3],\n",
       " [82, 1, 7],\n",
       " [1, 0, 1],\n",
       " [25, 0, 2]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simply making token is just one of the features of the node, I can add more \n",
    "x_test = [node_feature(a) for a in input_tree]\n",
    "x_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d31a66",
   "metadata": {},
   "source": [
    "### Creating of Graph Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a720661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.1\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Dataset, Data\n",
    "import torch_geometric\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "\n",
    "print(torch_geometric.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "248cf34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open(\"D:/Study/Intelligence And Learning/Reinforcement Learning/Project 1/deployment/src/Equation model/data/raw/linear_numeric1.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed2e5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = list(data.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ae3d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'90 + 41x ~ 77'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "534346c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [1, 2],\n",
       "        [1, 3],\n",
       "        [3, 4],\n",
       "        [3, 5],\n",
       "        [0, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = torch.tensor([[a,b] for [a,b,c] in eq if a!=-1])\n",
    "nodes = torch.tensor([node_feature(eq[i][2]) for i in range(len(eq))],dtype=torch.float32)\n",
    "edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6ed274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Data(x=nodes, edge_index=edge_index)\n",
    "d.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05143dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data = json.load(open(self.raw_paths[0]))\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return \"linear_numeric1.json\"\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'processed_data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        self.data = json.load(open(self.raw_paths[0]))\n",
    "        eqs = []\n",
    "\n",
    "        for (key,value) in self.data.items():\n",
    "            eqs.append(Data(\n",
    "                edge_index = torch.tensor([[a,b] for [a,b,c] in value if a!=-1]),\n",
    "                x=torch.tensor([node_feature(value[i][2]) for i in range(len(value))],dtype=torch.float32),\n",
    "                eq = key\n",
    "            ))\n",
    "        \n",
    "        torch.save(eqs, os.path.join(self.processed_dir, f\"processed_data.pt\"))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(os.path.join(self.processed_dir, f'processed_data.pt'), weights_only=False)\n",
    "        return data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9fce566",
   "metadata": {},
   "outputs": [],
   "source": [
    "yup = MyOwnDataset(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c49551d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(os.path.join(yup.processed_dir, f'processed_data.pt'), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff77c51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([84.,  1.,  7.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10].x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f057b737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-88 - 16x ~ -83'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10].eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4da540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b824e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(yup, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# When tree is passed as batches, it only return one action, so we have to pass that same batch, those same trees, again and again until the process gets terminated for a tree\n",
    "# it may happen that a processs is getting terminated for one tree but not for the other, how to handle that in batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add48858",
   "metadata": {},
   "source": [
    "### GNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abe282c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21903734a10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91a3c05c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba55cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, feature_size, model_params, num_output):\n",
    "        super(GNN, self).__init__()\n",
    "        embedding_size = model_params[\"model_embedding_size\"]\n",
    "        n_heads = model_params[\"model_attention_heads\"]\n",
    "        self.n_layers = model_params[\"model_layers\"]\n",
    "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
    "        top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
    "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
    "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "        edge_dim = model_params[\"model_edge_dim\"]\n",
    "\n",
    "        self.conv_layers = ModuleList([])\n",
    "        self.transf_layers = ModuleList([])\n",
    "        # self.pooling_layers = ModuleList([])   # I don't think that this dataset requires pooling layers, as my graph is not that much big, it's size is already very small, so this will lead to losing information\n",
    "        self.bn_layers = ModuleList([])\n",
    "\n",
    "        # Transformer layers (Convolving by making multi head attention, which has to be concatenated together, so size self.conv1 = (feature_size, n_heads*embedding_size))\n",
    "        self.conv1 = TransformerConv(feature_size, embedding_size, heads=n_heads, dropout=dropout_rate, edge_dim=edge_dim, beta=True)\n",
    "        \n",
    "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "        self.bn1 = BatchNorm1d(embedding_size)\n",
    "\n",
    "        # Other layers\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(TransformerConv(embedding_size, \n",
    "                                                    embedding_size, \n",
    "                                                    heads=n_heads, \n",
    "                                                    dropout=dropout_rate,\n",
    "                                                    edge_dim=edge_dim,\n",
    "                                                    beta=True))\n",
    "\n",
    "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "            self.bn_layers.append(BatchNorm1d(embedding_size))  # do batch normalization\n",
    "            # if i % self.top_k_every_n == 0:\n",
    "            #     # Dropout some node after some layers to reduce the size of graphs\n",
    "            #     self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
    "\n",
    "            # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "        self.linear3 = Linear(int(dense_neurons/2), num_output)  \n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        # Initial transformation\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(self.transf1(x))\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Holds the intermediate graph representations\n",
    "        global_representation = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "            x = torch.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x)\n",
    "\n",
    "            # Always aggregate last layer\n",
    "            # if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
    "            #     x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
    "            #         x, edge_index, edge_attr, batch_index\n",
    "            #         )\n",
    "                # Add current representation (global max and mean pooling)\n",
    "                # global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "            \n",
    "            # For this model we have n_layers=2, that's top_k_every_n doesn't make much sense here\n",
    "            global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "    \n",
    "        x = sum(global_representation)\n",
    "\n",
    "        # Output block\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5454ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNN(3,{\n",
    "    \"model_embedding_size\":16,\n",
    "    \"model_attention_heads\":2,\n",
    "    \"model_layers\":2,\n",
    "    \"model_dropout_rate\":0.3,\n",
    "    \"model_top_k_ratio\":2,\n",
    "    \"model_top_k_every_n\":2,\n",
    "    \"model_dense_neurons\":16,\n",
    "    \"model_edge_dim\":None,\n",
    "} ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2502d5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (conv_layers): ModuleList(\n",
       "    (0-1): 2 x TransformerConv(16, 16, heads=2)\n",
       "  )\n",
       "  (transf_layers): ModuleList(\n",
       "    (0-1): 2 x Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (bn_layers): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv1): TransformerConv(3, 16, heads=2)\n",
       "  (transf1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (linear2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (linear3): Linear(in_features=8, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f820930d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5888, -1.0927]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.zeros(7, dtype=torch.long)\n",
    "model(yup.get(0).x, yup.get(0).edge_attr, yup.get(0).edge_index.T, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "935d81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"model_embedding_size\":16,\n",
    "    \"model_attention_heads\":2,\n",
    "    \"model_layers\":2,\n",
    "    \"model_dropout_rate\":0.3,\n",
    "    \"model_top_k_ratio\":2,\n",
    "    \"model_top_k_every_n\":2,\n",
    "    \"model_dense_neurons\":16,\n",
    "    \"model_edge_dim\":None,\n",
    "}\n",
    "conv1 = TransformerConv(3, model_params[\"model_embedding_size\"], heads=model_params[\"model_attention_heads\"], dropout=model_params[\"model_dropout_rate\"], edge_dim=model_params[\"model_edge_dim\"], beta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "446d5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()  # best for multi-label binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for d in data_loader:\n",
    "    actions.append(model(d.x, d.edge_attr, d.edge_index.T,d.batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5277240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss for just 1 input & 1 output, in actual loss should come from some reinforcement program\n",
    "xmx = iter(data_loader)\n",
    "yup = next(xmx)\n",
    "outputs = model(yup.x, yup.edge_attr, yup.edge_index.T, yup.batch)\n",
    "yup.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c85bd3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0510, 1.0634]], grad_fn=<AddmmBackward0>), tensor([[1., 0.]]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = torch.tensor([[1,0]],dtype=torch.float32)\n",
    "outputs, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6188ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs, actual)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa2038ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8299, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2732b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making of model\n",
    "embedding_size = model_params[\"model_embedding_size\"]\n",
    "n_heads = model_params[\"model_attention_heads\"]\n",
    "n_layers = model_params[\"model_layers\"]\n",
    "dropout_rate = model_params[\"model_dropout_rate\"]\n",
    "top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
    "top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
    "dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "edge_dim = model_params[\"model_edge_dim\"]\n",
    "\n",
    "conv_layers = ModuleList([])\n",
    "transf_layers = ModuleList([])\n",
    "# pooling_layers = ModuleList([])   # I don't think that this dataset requires pooling layers, as my graph is not that much big, it's size is already very small, so this will lead to losing information\n",
    "bn_layers = ModuleList([])\n",
    "\n",
    "# Transformer layers (Convolving by making multi head attention, which has to be concatenated together, so size conv1 = (feature_size, n_heads*embedding_size))\n",
    "conv1 = TransformerConv(3, embedding_size, heads=n_heads, dropout=dropout_rate, edge_dim=edge_dim, beta=True)\n",
    "\n",
    "transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "bn1 = BatchNorm1d(embedding_size)\n",
    "\n",
    "# Other layers\n",
    "for i in range(n_layers):\n",
    "    conv_layers.append(TransformerConv(embedding_size, \n",
    "                                            embedding_size, \n",
    "                                            heads=n_heads, \n",
    "                                            dropout=dropout_rate,\n",
    "                                            edge_dim=edge_dim,\n",
    "                                            beta=True))\n",
    "\n",
    "    transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "    bn_layers.append(BatchNorm1d(embedding_size))  # do batch normalization\n",
    "    # if i % top_k_every_n == 0:\n",
    "    #     # Dropout some node after some layers to reduce the size of graphs\n",
    "    #     pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
    "\n",
    "    # Linear layers\n",
    "linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "linear3 = Linear(int(dense_neurons/2), 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f10fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,edge_attr,edge_index,batch_index=  yup.get(0).x, yup.get(0).edge_attr, yup.get(0).edge_index.T, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef27e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial transformation\n",
    "x = conv1(x, edge_index, edge_attr)\n",
    "x = torch.relu(transf1(x))\n",
    "x = bn1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f745c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holds the intermediate graph representations\n",
    "global_representation = []\n",
    "\n",
    "for i in range(n_layers):\n",
    "    x = conv_layers[i](x, edge_index, edge_attr)\n",
    "    x = torch.relu(transf_layers[i](x))\n",
    "    x = bn_layers[i](x)\n",
    "\n",
    "    # Always aggregate last layer\n",
    "    # if i == n_layers:\n",
    "        # Add current representation (global max and mean pooling)\n",
    "    global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ff4a892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = sum(global_representation)\n",
    "# Output block\n",
    "x = torch.relu(linear1(x))\n",
    "x = F.dropout(x, p=0.8, training=training)\n",
    "x = torch.relu(linear2(x))\n",
    "x = F.dropout(x, p=0.8, training=training)\n",
    "x = linear3(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ae264",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(yup.get(0).x, yup.get(0).edge_attr, yup.get(0).edge_index.T, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fedad14",
   "metadata": {},
   "source": [
    "## <center> Making of reinforcement environment: </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "161c5b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\juliacall\\__init__.py:61: UserWarning: torch was imported before juliacall. This may cause a segfault. To avoid this, import juliacall before importing torch. For updates, see https://github.com/pytorch/pytorch/issues/78829.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from juliacall import Main as jl\n",
    "jl.seval(\"using SymbolicUtils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e0cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ Info: Precompiling Symbolics [0c5d862f-8b57-4792-8d23-62f2024744c7] (cache misses: wrong dep version loaded (6), incompatible header (4))\n",
      "[ Info: Precompiling SciMLBasePythonCallExt [2797fd30-2078-5027-980c-4c2c8a19c528] \n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$$ \\begin{equation}\n",
       "\\left[\n",
       "\\begin{array}{c}\n",
       "x \\\\\n",
       "y \\\\\n",
       "z \\\\\n",
       "t \\\\\n",
       "\\end{array}\n",
       "\\right]\n",
       "\\end{equation}\n",
       " $$"
      ],
      "text/plain": [
       "4-element Vector{Num}:\n",
       " x\n",
       " y\n",
       " z\n",
       " t"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Main.var\"#f#9\"{var\"#f#6\"})(Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:54 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58.\n",
      "WARNING: Method definition kwcall(NamedTuple{names, T} where T<:Tuple where names, Main.var\"#f#9\"{var\"#f#6\"} where var\"#f#6\", Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:54 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58.\n",
      "WARNING: Method definition (::Main.var\"#f#9\"{var\"#f#6\"})(Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:62.\n",
      "WARNING: Method definition kwcall(NamedTuple{names, T} where T<:Tuple where names, Main.var\"#f#9\"{var\"#f#6\"} where var\"#f#6\", Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:62.\n"
     ]
    }
   ],
   "source": [
    "# jl.seval(\"\"\"\n",
    "#     include(\"../integral.jl\")\n",
    "#     include(\"../visualizer.jl\")\n",
    "#     include(\"../Symbolics_func.jl\")\n",
    "#     include(\"../Our_rules.jl\")\n",
    "\n",
    "#     @variables x y z t\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c53271c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_transport (generic function with 6 methods)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Method definition (::Main.var\"#f#1855\"{var\"#f#1852\"})(Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:54 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58.\n",
      "WARNING: Method definition kwcall(NamedTuple{names, T} where T<:Tuple where names, Main.var\"#f#1855\"{var\"#f#1852\"} where var\"#f#1852\", Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:54 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58.\n",
      "WARNING: Method definition (::Main.var\"#f#1855\"{var\"#f#1852\"})(Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:62.\n",
      "WARNING: Method definition kwcall(NamedTuple{names, T} where T<:Tuple where names, Main.var\"#f#1855\"{var\"#f#1852\"} where var\"#f#1852\", Any) in module Main at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:58 overwritten at d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\integral.jl:62.\n"
     ]
    }
   ],
   "source": [
    "jl.seval('include(\"linear_model.jl\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d14f252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-61 - 125x ~ 103']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss for just 1 input & 1 output, in actual loss should come from some reinforcement program\n",
    "xmx = iter(data_loader)\n",
    "yup = next(xmx)\n",
    "yup.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9f9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model takes action\n",
    "actual = torch.tensor([[1,0]],dtype=torch.float32).to(torch.int).detach().cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82bd2fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('-61 - 125x ~ 103', 1, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yup.eq[0],actual[0][0],actual[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D:/Study/Intelligence And Learning/Reinforcement Learning/Project 1/SymbolicModelsUtils.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"yu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8987bd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "JuliaError",
     "evalue": "UndefVarError: `x` not defined in `Main`\nStacktrace:\n [1] top-level scope\n   @ none:1\n [2] eval\n   @ .\\boot.jl:430 [inlined]\n [3] eval\n   @ .\\Base.jl:130 [inlined]\n [4] pyjlmodule_seval(self::Module, expr::Py)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:13\n [5] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\base.jl:67\n [6] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n   @ PythonCall.JlWrap.Cjl C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\C.jl:63",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJuliaError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtypeof(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:27\u001b[0m, in \u001b[0;36mseval\u001b[1;34m(self, expr)\u001b[0m\n\u001b[0;32m     25\u001b[0m         return ValueBase.__dir__(self) + self._jl_callmethod($(pyjl_methodnum(pyjlmodule_dir)))\n\u001b[0;32m     26\u001b[0m     def seval(self, expr):\n\u001b[1;32m---> 27\u001b[0m         return self._jl_callmethod($(pyjl_methodnum(pyjlmodule_seval)), expr)\n\u001b[0;32m     28\u001b[0m \"\"\",\n\u001b[0;32m     29\u001b[0m             @__FILE__(),\n",
      "\u001b[1;31mJuliaError\u001b[0m: UndefVarError: `x` not defined in `Main`\nStacktrace:\n [1] top-level scope\n   @ none:1\n [2] eval\n   @ .\\boot.jl:430 [inlined]\n [3] eval\n   @ .\\Base.jl:130 [inlined]\n [4] pyjlmodule_seval(self::Module, expr::Py)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:13\n [5] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\base.jl:67\n [6] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n   @ PythonCall.JlWrap.Cjl C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\C.jl:63"
     ]
    }
   ],
   "source": [
    "jl.seval(f\"\"\"\n",
    "         @variables x\n",
    "         typeof({yup.eq[0]})\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8161d313",
   "metadata": {},
   "outputs": [
    {
     "ename": "JuliaError",
     "evalue": "MethodError: no method matching *(::Int64, ::Nothing)\nThe function `*` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  *(::Any, ::Any, !Matched::Any, !Matched::Any...)\n   @ Base operators.jl:596\n  *(!Matched::Differential, ::Any)\n   @ Symbolics C:\\Users\\mohit\\.julia\\packages\\Symbolics\\kQzvO\\src\\diff.jl:56\n  *(::Any, !Matched::Differential)\n   @ Symbolics C:\\Users\\mohit\\.julia\\packages\\Symbolics\\kQzvO\\src\\diff.jl:55\n  ...\n\nStacktrace:\n [1] linear_transport(expr_tree::Vector{Tuple{typeof(+), AbstractVector{Any}}}, side::Int64, node::Int64)\n   @ Main d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\Equation model\\linear_model.jl:26\n [2] linear_transport(expr::Equation, side::Int64, node::Int64)\n   @ Main d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\Equation model\\linear_model.jl:48\n [3] top-level scope\n   @ none:1\n [4] eval\n   @ .\\boot.jl:430 [inlined]\n [5] eval\n   @ .\\Base.jl:130 [inlined]\n [6] pyjlmodule_seval(self::Module, expr::Py)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:13\n [7] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\base.jl:67\n [8] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n   @ PythonCall.JlWrap.Cjl C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\C.jl:63",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJuliaError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This will return the modified tree expression which has to again fed to the tree, so that it can again give the actions and node \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mjl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinear_transport(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43myup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mactual\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mactual\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:27\u001b[0m, in \u001b[0;36mseval\u001b[1;34m(self, expr)\u001b[0m\n\u001b[0;32m     25\u001b[0m         return ValueBase.__dir__(self) + self._jl_callmethod($(pyjl_methodnum(pyjlmodule_dir)))\n\u001b[0;32m     26\u001b[0m     def seval(self, expr):\n\u001b[1;32m---> 27\u001b[0m         return self._jl_callmethod($(pyjl_methodnum(pyjlmodule_seval)), expr)\n\u001b[0;32m     28\u001b[0m \"\"\",\n\u001b[0;32m     29\u001b[0m             @__FILE__(),\n",
      "\u001b[1;31mJuliaError\u001b[0m: MethodError: no method matching *(::Int64, ::Nothing)\nThe function `*` exists, but no method is defined for this combination of argument types.\n\nClosest candidates are:\n  *(::Any, ::Any, !Matched::Any, !Matched::Any...)\n   @ Base operators.jl:596\n  *(!Matched::Differential, ::Any)\n   @ Symbolics C:\\Users\\mohit\\.julia\\packages\\Symbolics\\kQzvO\\src\\diff.jl:56\n  *(::Any, !Matched::Differential)\n   @ Symbolics C:\\Users\\mohit\\.julia\\packages\\Symbolics\\kQzvO\\src\\diff.jl:55\n  ...\n\nStacktrace:\n [1] linear_transport(expr_tree::Vector{Tuple{typeof(+), AbstractVector{Any}}}, side::Int64, node::Int64)\n   @ Main d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\Equation model\\linear_model.jl:26\n [2] linear_transport(expr::Equation, side::Int64, node::Int64)\n   @ Main d:\\Study\\Intelligence And Learning\\Reinforcement Learning\\Project 1\\deployment\\src\\Equation model\\linear_model.jl:48\n [3] top-level scope\n   @ none:1\n [4] eval\n   @ .\\boot.jl:430 [inlined]\n [5] eval\n   @ .\\Base.jl:130 [inlined]\n [6] pyjlmodule_seval(self::Module, expr::Py)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\module.jl:13\n [7] _pyjl_callmethod(f::Any, self_::Ptr{PythonCall.C.PyObject}, args_::Ptr{PythonCall.C.PyObject}, nargs::Int64)\n   @ PythonCall.JlWrap C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\base.jl:67\n [8] _pyjl_callmethod(o::Ptr{PythonCall.C.PyObject}, args::Ptr{PythonCall.C.PyObject})\n   @ PythonCall.JlWrap.Cjl C:\\Users\\mohit\\.julia\\packages\\PythonCall\\Nr75f\\src\\JlWrap\\C.jl:63"
     ]
    }
   ],
   "source": [
    "# This will return the modified tree expression which has to again fed to the tree, so that it can again give the actions and node \n",
    "jl.seval(f\"linear_transport({yup.eq[0]}, {actual[0][0]}, {actual[0][1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ccade6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
